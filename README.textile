h1. Hearst Challenge

This project documents the participation of Jason Brownlee in the "Hearst Analytics Challenge":http://hearstchallenge.com/


h2. Test Harness

The test harness is currently composed of a fixed random selection 20K 2009 records from the template_mo2 table.

h2. Nearest Neighbour Experiments

Nearest neighbour experiments against the test harness.

h3. Baseline

The following provides a baseline of average title/year/month sales for each record.

|_. Model |_. Coverage |_. RMSE |
| Baseline[k=999999] | 100% | 26.756|

h3. Chain

The following table of results considers pseudo random neighbourhoods of stores with the same chain.

|_. Model |_. Coverage |_. RMSE |
| ChainNNSales[k=1] | 98.555% | 49.61|
| ChainNNSales[k=3] | 98.555% | 25.74|
| ChainNNSales[k=5] | 98.555% | 24.176|
| ChainNNSales[k=10] | 98.555% | 22.106|
| ChainNNSales[k=50] | 98.555% | 21.719|
| ChainNNSales[k=100] | 98.555% | 21.624|
| ChainNNSales[k=500] | 98.555% | 21.574|
| ChainNNSales[k=1000] | 98.555% | 21.57|
| ChainNNSales[k=999999] | 98.555% | 21.569|

The results show that averaging against all stores with the same chain provides the best results.

h3. Age Statistics

|_. Model |_. Coverage |_. RMSE |
| AgeChainNNSales[k=1] | 98.32% | 24.968|
| AgeChainNNSales[k=3] | 98.32% | 23.124|
| AgeChainNNSales[k=5] | 98.32% | 21.246|
| AgeChainNNSales[k=7] | 98.32% | 20.861|
| AgeChainNNSales[k=10] | 98.32% | 21.44|
| AgeChainNNSales[k=15] | 98.32% | 22.005|
| AgeChainNNSales[k=20] | 98.32% | 21.569|

h3. Dwelling Size Statistics

|_. Model |_. Coverage |_. RMSE |
| DwellingSizeChainNNSales[k=1] | 98.32% | 25.592|
| DwellingSizeChainNNSales[k=3] | 98.32% | 22.957|
| DwellingSizeChainNNSales[k=5] | 98.32% | 21.421|
| DwellingSizeChainNNSales[k=7] | 98.32% | 21.062|
| DwellingSizeChainNNSales[k=10] | 98.32% | 21.458|
| DwellingSizeChainNNSales[k=15] | 98.32% | 21.944|
| DwellingSizeChainNNSales[k=20] | 98.32% | 21.536|

h3. Dwelling Type Statistics

|_. Model |_. Coverage |_. RMSE |
| DwellingTypeChainNNSales[k=1] | 98.32% | 25.617|
| DwellingTypeChainNNSales[k=3] | 98.32% | 23.097|
| DwellingTypeChainNNSales[k=5] | 98.32% | 21.418|
| DwellingTypeChainNNSales[k=7] | 98.32% | 21.055|
| DwellingTypeChainNNSales[k=10] | 98.32% | 21.533|
| DwellingTypeChainNNSales[k=15] | 98.32% | 21.741|
| DwellingTypeChainNNSales[k=20] | 98.32% | 21.547|

h3. Education Statistics

|_. Model |_. Coverage |_. RMSE |
| EducationChainNNSales[k=1] | 98.32% | 25.526|
| EducationChainNNSales[k=3] | 98.32% | 22.339|
| EducationChainNNSales[k=5] | 98.32% | 21.239|
| EducationChainNNSales[k=7] | 98.32% | 20.734|
| EducationChainNNSales[k=10] | 98.32% | 21.292|
| EducationChainNNSales[k=15] | 98.32% | 21.858|
| EducationChainNNSales[k=20] | 98.32% | 21.505|

h3. Gender Statistics

|_. Model |_. Coverage |_. RMSE |
| GenderChainNNSales[k=1] | 98.32% | 25.826|
| GenderChainNNSales[k=3] | 98.32% | 23.786|
| GenderChainNNSales[k=5] | 98.32% | 21.524|
| GenderChainNNSales[k=7] | 98.32% | 21.062|
| GenderChainNNSales[k=10] | 98.32% | 21.688|
| GenderChainNNSales[k=15] | 98.32% | 22.091|
| GenderChainNNSales[k=20] | 98.32% | 21.589|

h3. Homeowner Statistics

|_. Model |_. Coverage |_. RMSE |
| HomeownerChainNNSales[k=1] | 98.32% | 24.878|
| HomeownerChainNNSales[k=3] | 98.32% | 22.715|
| HomeownerChainNNSales[k=5] | 98.32% | 21.412|
| HomeownerChainNNSales[k=7] | 98.32% | 20.95|
| HomeownerChainNNSales[k=10] | 98.32% | 21.52|
| HomeownerChainNNSales[k=15] | 98.32% | 21.985|
| HomeownerChainNNSales[k=20] | 98.32% | 21.519|

h3. Household Status Statistics

|_. Model |_. Coverage |_. RMSE |
| HouseholdChainStatusNNSales[k=1] | 98.32% | 25.672|
| HouseholdChainStatusNNSales[k=3] | 98.32% | 22.664|
| HouseholdChainStatusNNSales[k=5] | 98.32% | 21.254|
| HouseholdChainStatusNNSales[k=7] | 98.32% | 20.859|
| HouseholdChainStatusNNSales[k=10] | 98.32% | 21.368|
| HouseholdChainStatusNNSales[k=15] | 98.32% | 21.955|
| HouseholdChainStatusNNSales[k=20] | 98.32% | 21.545|

h3. Income Statistics

|_. Model |_. Coverage |_. RMSE |
| IncomeChainNNSales[k=1] | 98.32% | 24.757|
| IncomeChainNNSales[k=3] | 98.32% | 22.761|
| IncomeChainNNSales[k=5] | 98.32% | 21.34|
| IncomeChainNNSales[k=7] | 98.32% | 20.915|
| IncomeChainNNSales[k=10] | 98.32% | 21.371|
| IncomeChainNNSales[k=15] | 98.32% | 21.961|
| IncomeChainNNSales[k=20] | 98.32% | 21.544|

h3. Marital Status Statistics

|_. Model |_. Coverage |_. RMSE |
| MaritalStatusChainNNSales[k=1] | 98.32% | 25.033|
| MaritalStatusChainNNSales[k=3] | 98.32% | 22.628|
| MaritalStatusChainNNSales[k=5] | 98.32% | 21.259|
| MaritalStatusChainNNSales[k=7] | 98.32% | 20.83|
| MaritalStatusChainNNSales[k=10] | 98.32% | 21.581|
| MaritalStatusChainNNSales[k=15] | 98.32% | 22.014|
| MaritalStatusChainNNSales[k=20] | 98.32% | 21.559|

h3. Mvh Statistics

|_. Model |_. Coverage |_. RMSE |
| MvhStatusChainNNSales[k=1] | 98.32% | 24.452|
| MvhStatusChainNNSales[k=3] | 98.32% | 21.536|
| MvhStatusChainNNSales[k=5] | 98.32% | 21.095|
| MvhStatusChainNNSales[k=7] | 98.32% | 21.193|
| MvhStatusChainNNSales[k=10] | 98.32% | 21.375|
| MvhStatusChainNNSales[k=15] | 98.32% | 21.984|
| MvhStatusChainNNSales[k=20] | 98.32% | 21.624|

h3. Occupation Statistics

|_. Model |_. Coverage |_. RMSE |
| OccupationChainNNSales[k=1] | 98.32% | 24.543|
| OccupationChainNNSales[k=3] | 98.32% | 21.769|
| OccupationChainNNSales[k=5] | 98.32% | 21.014|
| OccupationChainNNSales[k=7] | 98.32% | 20.912|
| OccupationChainNNSales[k=10] | 98.32% | 21.402|
| OccupationChainNNSales[k=15] | 98.32% | 21.83|
| OccupationChainNNSales[k=20] | 98.32% | 21.43|

h3. Residence Statistics

|_. Model |_. Coverage |_. RMSE |
| ResidenceChainNNSales[k=1] | 98.32% | 25.742|
| ResidenceChainNNSales[k=3] | 98.32% | 22.969|
| ResidenceChainNNSales[k=5] | 98.32% | 21.446|
| ResidenceChainNNSales[k=7] | 98.32% | 21.135|
| ResidenceChainNNSales[k=10] | 98.32% | 21.562|
| ResidenceChainNNSales[k=15] | 98.32% | 22.071|
| ResidenceChainNNSales[k=20] | 98.32% | 21.598|

h3. Size Statistics

|_. Model |_. Coverage |_. RMSE |
| SizeChainNNSales[k=1] | 98.32% | 25.569|
| SizeChainNNSales[k=3] | 98.32% | 22.961|
| SizeChainNNSales[k=5] | 98.32% | 21.295|
| SizeChainNNSales[k=7] | 98.32% | 21.05|
| SizeChainNNSales[k=10] | 98.32% | 21.685|
| SizeChainNNSales[k=15] | 98.32% | 22.215|
| SizeChainNNSales[k=20] | 98.32% | 21.684|

h3. Summarized Area Level Statistics

|_. Model |_. Coverage |_. RMSE |
| SummarizedChainNNSales[k=1] | 98.535% | 23.632|
| SummarizedChainNNSales[k=3] | 98.535% | 21.233|
| SummarizedChainNNSales[k=5] | 98.535% | 20.911|
| SummarizedChainNNSales[k=7] | 98.535% | 20.486|
| SummarizedChainNNSales[k=10] | 98.535% | 20.59|
| SummarizedChainNNSales[k=15] | 98.535% | 21.317|
| SummarizedChainNNSales[k=20] | 98.535% | 21.318|

h3. Vehicles Statistics

|_. Model |_. Coverage |_. RMSE |
| VehiclesChainNNSales[k=1] | 98.175% | 23.755|
| VehiclesChainNNSales[k=3] | 98.175% | 20.953|
| VehiclesChainNNSales[k=5] | 98.175% | 21.467|
| VehiclesChainNNSales[k=7] | 98.175% | 21.38|
| VehiclesChainNNSales[k=10] | 98.175% | 21.064|
| VehiclesChainNNSales[k=15] | 98.175% | 20.875|
| VehiclesChainNNSales[k=20] | 98.175% | 20.885|


h3. Combinations

Model: MvhAndEduStatusChainNNSales

|_. Model |_. Coverage |_. RMSE |
| MvhAndEduStatusChainNNSales[k=1] | 98.32% | 24.015|
| MvhAndEduStatusChainNNSales[k=3] | 98.32% | 21.889|
| MvhAndEduStatusChainNNSales[k=5] | 98.32% | 21.008|
| MvhAndEduStatusChainNNSales[k=7] | 98.32% | 20.969|
| MvhAndEduStatusChainNNSales[k=10] | 98.32% | 21.254|
| MvhAndEduStatusChainNNSales[k=15] | 98.32% | 21.803|

Model: MvhStatusAndVehiclesChainNNSales

|_. Model |_. Coverage |_. RMSE |
| MvhStatusAndVehiclesChainNNSales[k=1] | 98.175% | 23.896|
| MvhStatusAndVehiclesChainNNSales[k=3] | 98.175% | 20.89|
| MvhStatusAndVehiclesChainNNSales[k=5] | 98.175% | 21.061|
| MvhStatusAndVehiclesChainNNSales[k=7] | 98.175% | 21.19|
| MvhStatusAndVehiclesChainNNSales[k=10] | 98.175% | 21.23|
| MvhStatusAndVehiclesChainNNSales[k=15] | 98.175% | 21.187|

Model: SummarizedAndEduChainNNSales

|_. Model |_. Coverage |_. RMSE |
| SummarizedAndEduChainNNSales[k=1] | 98.3% | 23.942|
| SummarizedAndEduChainNNSales[k=3] | 98.3% | 21.117|
| SummarizedAndEduChainNNSales[k=5] | 98.3% | 20.43|
| SummarizedAndEduChainNNSales[k=7] | 98.3% | 20.402|
| SummarizedAndEduChainNNSales[k=10] | 98.3% | 21.64|
| SummarizedAndEduChainNNSales[k=15] | 98.3% | 21.829|

Model: SummarizedAndMhvChainNNSales

|_. Model |_. Coverage |_. RMSE |
| SummarizedAndMhvChainNNSales[k=1] | 98.3% | 24.099|
| SummarizedAndMhvChainNNSales[k=3] | 98.3% | 21.148|
| SummarizedAndMhvChainNNSales[k=5] | 98.3% | 20.453|
| SummarizedAndMhvChainNNSales[k=7] | 98.3% | 20.38|
| SummarizedAndMhvChainNNSales[k=10] | 98.3% | 21.577|
| SummarizedAndMhvChainNNSales[k=15] | 98.3% | 21.666|

Model: VehiclesAndEducationChainNNSales

|_. Model |_. Coverage |_. RMSE |
| VehiclesAndEducationChainNNSales[k=1] | 98.175% | 24.121|
| VehiclesAndEducationChainNNSales[k=3] | 98.175% | 21.175|
| VehiclesAndEducationChainNNSales[k=5] | 98.175% | 21.185|
| VehiclesAndEducationChainNNSales[k=7] | 98.175% | 21.165|
| VehiclesAndEducationChainNNSales[k=10] | 98.175% | 21.237|
| VehiclesAndEducationChainNNSales[k=15] | 98.175% | 21.207|

Model: VehiclesAndSummarizedChainNNSales

|_. Model |_. Coverage |_. RMSE |
| VehiclesAndSummarizedChainNNSales[k=1] | 98.175% | 23.366|
| VehiclesAndSummarizedChainNNSales[k=3] | 98.175% | 20.822|
| VehiclesAndSummarizedChainNNSales[k=5] | 98.175% | 20.386|
| VehiclesAndSummarizedChainNNSales[k=7] | 98.175% | 20.175|
| VehiclesAndSummarizedChainNNSales[k=10] | 98.175% | 20.174|
| VehiclesAndSummarizedChainNNSales[k=15] | 98.175% | 20.325|

Model: MvhAndEduAndSummarizedAndVehiclesStatusChainNNSales

|_. Model |_. Coverage |_. RMSE |
| MvhAndEduAndSummarizedAndVehiclesStatusChainNNSales[k=1] | 98.175% | 23.29|
| MvhAndEduAndSummarizedAndVehiclesStatusChainNNSales[k=3] | 98.175% | 20.437|
| MvhAndEduAndSummarizedAndVehiclesStatusChainNNSales[k=5] | 98.175% | 20.343|
| MvhAndEduAndSummarizedAndVehiclesStatusChainNNSales[k=7] | 98.175% | 20.174|
| MvhAndEduAndSummarizedAndVehiclesStatusChainNNSales[k=10] | 98.175% | 20.34|
| MvhAndEduAndSummarizedAndVehiclesStatusChainNNSales[k=15] | 98.175% | 20.493|




h2. Provided Data

This section summarized the data that was provided on October 14th 2010.

The data includes  Sales, Issue, Store/Chain, Wholesaler and Zip+4 data between 2006 and 2009. The validation dataset is a subset of the broader modelling dataset.

h3. Data Files

* Data_Description_and_Problem_Statement for_Hearst_Challenge.xls : provides an summary of the problem, the data, and the relationship between the validation data tables.
* zip_plus4_data_[1-5].zip (5 files) : ?

h3. Modelling Data

The modelling data includes a large historic dataset from 2006 to 2009.

* Hearst_Challenge_Modeling_CSV_Files.zip : package of 4 modeling datasets8
** issue_mo_dataset.csv : 51885 records of 6 attributes (issue_key, CAN_COV_PRC, ISS_CD, US_COV_PRC, ON_SALE_DATE, OFF_SALE_DATE) with CAN_COV_PRC missing on many records.
** sales_mo_dataset.csv :  10,929,955 records of 9 attributes (wholesaler_key, chain_key, store_key, issue_key, dollar_volume, draw, returns, sales, title_key)
** store_mo_dataset.csv : 40,390 records of x (117?) attributes (...)
** wholesaler_mo_dataset.csv : 129 records of 3 attributes (wholesaler_key, CITY, ST)

h3. Validation Data

The validation dataset is a subset of the modelling dataset and is intended to be used to submit to the website.

* Hearst_Challenge_Validation_CSV_Files.zip : package containing 3 validation dataset
** sales_vd_dataset.csv : 709,265 records of 5 attributes (wholesaler_key, chain_key, store_key, issue_key, title_key).
** store_vd_dataset.csv : 2,500 records of 117 attributes (...)
** template_for_submission.csv : 492,100 records of 4 attributes (store_key, title_key, year_month, sales_total). This is the submission file without the predictions (order may be important).

Questions
* Is the validation dataset a true sub-set of the modelling data, if so, surely the monthly sales numbers are provided in the modelling dataset and can be used as a submission - achieving an RMSE of zero.

h3. Competition Data

A third set of data (the holdout set) will be provided at the end of the competition and will be used to determine the winner of the competition. This third dataset will include data from outside the 2006-2009 time period.

h3. Summary

Submissions are assessed based on the RMSE of the sales in the submission.

The objective is to predict the number of magazine units sold at a given store during a given month. Historic information can be deduced from the sales table, specifically the issue_key, store_key, and sales. The table appears to be missing date information. The date of the sames information could be deduced from the issue on-sale/off-sale dates. 

The problem is to predict monthly store/issue/sales numbers with no past information for specific months, only for issues? This means we don't know how issues behave over time, only holistically.

There is very little information about the magazines themselves. Most of the information is about the stores including the demographics for the store area and the store wholesaler. We have sales information for the store-issue and we have some very basic information about the issue such as its price. We have a magazine title key in the sale data to which to relate issues to each other.

We have a large amount of historic data and we are given a data sub-set of stores and sales data from which predictions must be made. It can be assumed that the provided data is a sub-set of the broader dataset, although has been removed. 

h2. Validation Data

h3. Summary Statistics: template_vd

The following provides summary statistics for the validation dataset (template_vd).

|_. Measures |_. Values |
| Total Records | 492100 |
| Total Stores | 2500 |
| Total Titles | 10 |
| Total Months | 29 |

|_. Measures |_. Values |
| Average Records/Month | 16968 |
| Average Stores/Month | 2468 |
| Average Titles/Month | 9 |
| Average Records/Store | 196 |
| Average Titles/Store | 7 |
| Average Records/Title | 49210 |
| Average Stores/Title | 1950 |

h3. Summary Statistics: sales_vd

The following provides summary statistics for the validation dataset (sales_vd).

|_. Measures |_. Values |
| Total Records | 709265 |
| Total Wholesalers | 40 |
| Total Chains | 85 |
| Total Stores | 2456 |
| Total Issues | 405 |
| Total Titles | 10 |

|_. Measures |_. Values |
| Average Records/Title | 70926 |
| Average Issues/Title | 40 |
| Average Stores/Title | 1945 |
| Average Chains/Title | 66 |
| Average Wholesalers/Title | 35 |

|_. Measures |_. Values |
| Average Records/Issue | 1751 |
| Average Wholesalers/Issue | 27 |
| Average Chains/Issue | 57 |
| Average Stores/Issue | 1719 |
| Average Titles/Issue | 1 |

|_. Measures |_. Values |
| Average Records/Store | 288 |
| Average Wholesalers/Store | 1 |
| Average Chains/Store | 1 |
| Average Issues/Store | 283 |
| Average Titles/Store | 7 |

|_. Measures |_. Values |
| Average Records/Chain | 8344 |
| Average Wholesalers/Chain | 2 |
| Average Stores/Chain | 28 |
| Average Issues/Chain | 272 |
| Average Titles/Chain | 7 |

|_. Measures |_. Values |
| Average Records/Wholesaler | 17731 |
| Average Store/Wholesaler | 108 |
| Average Chains/Wholesaler | 4 |
| Average Issues/Wholesaler | 275 |
| Average Titles/Wholesaler | 8 |


h3. Summary Statistics: stores_vd

The following provides summary statistics for the validation dataset (stores_vd).

TODO


h3. Summary

The required approach for the competition may be collaborative filtering where nearest-neighbour issues/titles are extracted from the historic corpus and used for prediction.

Are any of the titles in the larger corpus?
select count(*) from 
	(select distinct(sm.title_key) as sm_title_key from sales_mo sm) as a, 
	(select distinct(sd.title_key) as sd_title_key from sales_vd sd) as b
	where a.sm_title_key = b.sd_title_key;
- yes all 10

Are there any issues in the larger corpus?
select count(*) from 
	(select distinct(sm.issue_key) as sm_issue_key from sales_mo sm) as a, 
	(select distinct(sd.issue_key) as sd_issue_key from sales_vd sd) as b
	where a.sm_issue_key = b.sd_issue_key;
- yes all 405

this assumes a 1-to-1 relationship between issues and titles (an issue only belongs to one title)
- stats for both sales data tables confirm this

Are there any issues from the same months from the larger corpus?
no
select vd.* 
from template_mo mo, template_vd2 vd
where mo.store_key=vd.store_key 
and mo.title_key=vd.title_key
and mo.on_year=vd.on_year
and mo.on_month=vd.on_month

what overlap is there?
- no stores
- titles yes
- months yes
- years yes


h2. Test Methodology

I guess cross-validate (n-fold, hold one out) the validation data







h2. Magazine

An analysis of magazine information

h2. Stores

An analysis of store information

h2. Sales

Summary statistics of the sales_mo table

|_. Measures |_. Values |
| Total Records | 10929954 |
| Total Wholesalers | 65 |
| Total Chains | 1013 |
| Total Stores | 39374 |
| Total Issues | 427 |
| Total Titles | 10 |

|_. Measures |_. Values |
| Average Records/Title | 1092995 |
| Average Issues/Title | 42 |
| Average Stores/Title | 30952 |
| Average Chains/Title | 818 |
| Average Wholesalers/Title | 60 |

|_. Measures |_. Values |
| Average Records/Issue | 25597 |
| Average Wholesalers/Issue | 46 |
| Average Chains/Issue | 686 |
| Average Stores/Issue | 25334 |
| Average Titles/Issue | 1 |

|_. Measures |_. Values |
| Average Records/Store | 277 |
| Average Wholesalers/Store | 1 |
| Average Chains/Store | 1 |
| Average Issues/Store | 274 |
| Average Titles/Store | 7 |

|_. Measures |_. Values |
| Average Records/Chain | 10789 |
| Average Wholesalers/Chain | 2 |
| Average Stores/Chain | 38 |
| Average Issues/Chain | 289 |
| Average Titles/Chain | 8 |

|_. Measures |_. Values |
| Average Records/Wholesaler | 168153 |
| Average Store/Wholesaler | 772 |
| Average Chains/Wholesaler | 35 |
| Average Issues/Wholesaler | 307 |
| Average Titles/Wholesaler | 9 |

there is negative sales data, it should be ignored. see "Clarification regarding negative sales values in the sales_mo_dataset table":http://hearstchallenge.com/index.php?option=com_ccboard&view=postlist&forum=20&topic=100&Itemid=&task_id=

are there any issues that span more than one month?
- yes, heaps: 44371
select * from issue_mo
where month(on_sale_date) <> month(off_sale_date)

This means that special handling is needed when preparing the sales data
No, it means there may be issue interference effects that could be modelled



h2. Demographics

An analysis of demographics information

h2. Issue

An analysis of issue information

h2. Wholesaler

An analysis of wholesaler information


h2. Prediction

predicting for the verification submission dataset

h3. sales

h4. average sales

average of all sales is 9.9273 
gives an RMSE of 20.1289


h4. year/month average sales

How many distinct year/months are there in vd?
* 29
** select count(distinct on_year, on_month) from template_vd2

Is there sales data for all instances?
* yes, all 29 records can join
** select count(*) from (select distinct on_year, on_month from template_vd2) vd natural join (select distinct on_year, on_month from template_mo) mo

What is the query to get the average sales?

select vd.on_year, vd.on_month, avg(mo.sales_total) 
from (select distinct on_year, on_month from template_vd2) vd, template_mo mo
where vd.on_year = mo.on_year and vd.on_month = mo.on_month
group by vd.on_year, vd.on_month


h4. title/year/month average sales

distinct issue/year/month in the verification data
* select title_key, on_year, on_month from template_vd2 group by title_key, on_year, on_month
* select count(*) from (select title_key, on_year, on_month from template_vd2 group by title_key, on_year, on_month) as abc;
There are 283 distinct issue/year/month for 492,100 records

we can take the average sales across issue/year/month for all stores in the sales_mo database:
* select mo.title_key as title_key, mo.on_year as on_year, mo.on_month as on_month, avg(mo.sales_total) as sales_total from template_mo mo, (select title_key, on_year, on_month from template_vd2 group by title_key, on_year, on_month) as vd where mo.title_key=vd.title_key and mo.on_year=vd.on_year and mo.on_month=vd.on_month group by title_key, on_year, on_month

How many of these distinct 283 records exist in the sales_mo database?
* we can take a count of the above query - get the number of averages calculated
* the result is 283 - that is all cases covered

the submission rmse is 18.06

h4. wholesaler/title/year/month average sales

In this case we are interested in aggregating mo store/title/year/month average sales by wholesaler. The idea is to join vd stores to this data by their store/title wholesaler. 

Firstly, which vd stores can and cannot be joined to the mo data?

There are 2 vd wholesalers, 45 of which do not exist in the mo dataset (wholesaler_key: 22, 67)
* select vd.wholesaler_key from (select distinct(wholesaler_key) from wholesaler_store_vd) vd where vd.wholesaler_key not in (select distinct(wholesaler_key) from wholesaler_store_mo);
* select count(distinct wholesaler_key) from wholesaler_store_vd

This effects 38 of 2500 vd stores
* select count(distinct store_key) from wholesaler_store_vd where wholesaler_key in (22, 67)
* select count(distinct store_key) from wholesaler_store_vd

This effects 155 of 19502 vs store-titles
* select count(distinct store_key, title_key) from wholesaler_store_vd where wholesaler_key in (22, 67)
* select count(distinct store_key, title_key) from wholesaler_store_vd

This is a little too high-level. We need to test the specific join cases. 

How many discrete wholesaler/title/year/month records are there in the vd dataset? 
* There are 283 distinct title/year/month records of 492,100 total records
** select count(distinct title_key, on_year, on_month) from template_vd2
* There are 11705 distinct wholesaler/title/year/month records
** select count(distinct t.title_key, t.on_year, t.on_month, w.wholesaler_key) from template_vd2 t, wholesaler_store_vd w where w.title_key = t.title_key and w.store_key = t.store_key

How many of these can and cannot be joined to to the mo dataset?
* 11158 distinct wholesaler/title/year/month records can be joined from vd to mo, leaving 548 records.
** select count(*) from (select distinct t.title_key, t.on_year, t.on_month, w.wholesaler_key from template_vd2 t, wholesaler_store_vd w where w.title_key = t.title_key  and w.store_key = t.store_key) a_vd NATURAL JOIN (select distinct t.title_key, t.on_year, t.on_month, w.wholesaler_key from template_mo t, wholesaler_store_mo w where w.title_key = t.title_key and w.store_key = t.store_key) a_mo

What is the query to calculate the average sales for each case in a single query?
select vd.title_key, vd.on_year, vd.on_month, avg(mo.sales_total) 
from
(select distinct t.title_key, t.on_year, t.on_month, w.wholesaler_key
from template_vd2 t, wholesaler_store_vd w
where w.title_key = t.title_key 
and w.store_key = t.store_key) vd,
(select t.title_key, t.on_year, t.on_month, t.sales_total,  w.wholesaler_key
from template_mo t, wholesaler_store_mo w
where w.title_key = t.title_key 
and w.store_key = t.store_key) mo
where vd.wholesaler_key=mo.wholesaler_key and vd.title_key=mo.title_key and vd.on_year=mo.on_year and vd.on_month=mo.on_month
group by vd.wholesaler_key, vd.title_key, vd.on_year, vd.on_month

What is the strategy?
- prepare an in memory table of distinct store/title=>wholesaler id's for the vd data
- prepare year/month sales averages as a fallback
- prepare title/year/month sales averages as a fallback
- prepare wholesaler/title/year/month sales averages
- find the best fit for each entry in the test data

The rmse was 17.4556


h4. chain/title/year/month average sales

There are 282 distinct chains in the sales_vd table

How many chains in the template data are not in the mo data?
* there are 98 of 282 that are not in the mo data
* select count(*) from (select distinct chain_key from sales_vd) vd where chain_key not in (select distinct chain_key from sales_mo);

is there a one-to-one between a store and a chain?
* 0
* select * from (select store_key, count(distinct chain_key) as c from sales_mo group by store_key) where c>1

performing a cascade through chain, wholesaler, title based results, the RMSE was 13.3009



h2. Exploration

The exploration of hypotheses on the model data.

h3. Variance Experiments

Variance in the sales totals for the ~3M records in the 2009 model data and various aggregation strategies.

|_. Aggregation |_. Average Difference |
| Year/Month | 10.31046 |
| Title/Year/Month | 8.96702 |
| Wholesaler/Title/Year/Month | 8.36551 |
| Chain/Title/Year/Month | 5.35888 |
| StoreType/Title/Year/Month | 6.83674 |
| City/Title/Year/Month | 7.78722 | 
| State/Title/Year/Month | 8.77748 | 
| ZipCode/Title/Year/Month | ? | 
| State/Chain/Title/Year/Month | 5.05807 |
| State/StoreType/Title/Year/Month | 6.32165 |
| City/Chain/Title/Year/Month | 2.1031 |

some of these are no good - vd data does not have the same cities or states - well, it does have the same city names, but they are in different states.

h3. Store NN

The idea here is to investigate the relationships between stores based on their demographics. Specifically find stores that are similar by store area demographics information. The the predictability of similar stores sales information for a given title-year-month. This means, under these conditions, that another store can only be considered a neighbour if it also has a title-year-month combination in common. In fact it would be interesting to know the average number of possible candidates exists for each combination in the validation dataset - it is likely we can only get K>3 for a few stores.

Side note: this also hints that neighbours could be found by seeking stores with similar title selling patterns (can this be determined?)

Data
* there are 283 distinct cases of title-year-month in the template_vd table
* all of them can join to the template_mo table
* the average number of matches for each record into the template_mo table is 331.251
** one may assume that each record represents a different store, so that is ~331 stores per record 
* we can ease the initial query for each record by preparing a secondary table that only contains matching records and the relevant store metadata to be matched against.
** perhaps all meta data?
* how many distinct records are in that set?
** there are 283 distinct records in the set
** there are 39,374 distinct stores in the set

It also occurs to me that candidate stores can be prepared, so the computation process would: 1) pre-compute the store metadata needed for a submission and 2) pre-compute relevant stores for each record. From this we can ad-hoc aggregate sales information for stores with an ordered calculated distance score.

too slow






h2.  Licenses

(c) Copyright 2010 Jason Brownlee. Some Rights Reserved.

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/au/">
        <img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/2.5/au/88x31.png" />
</a>

This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/au/">
Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License</a>.
